{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "CarDetection_Aerial_Imagery.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "machine_shape": "hm"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vD8EDdm27aBP",
        "colab_type": "text"
      },
      "source": [
        "Dataset: Cars Overhead with Context (COWC) - https://gdo152.llnl.gov/cowc/\n",
        "\n",
        "Upload the dataste in Google Drive and mount the drive in Google Colab for easy access to the dataset. Uploading the dataset folders in Google Colab is takes a lot of time and will be erased when the session gets terminated."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yJ0caE2f15pf",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!unzip /content/drive/\"My Drive\"/Detection_Patches.zip"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rc85cmaM8Hwp",
        "colab_type": "text"
      },
      "source": [
        "Import all the necessary libraries and packages"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "H-57GakA3tDg",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from __future__ import print_function, division\n",
        "import os\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "import torchvision.models as models\n",
        "import torch.nn.functional as F\n",
        "import pandas as pd\n",
        "from skimage import io\n",
        "import numpy as np\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "from torchvision import transforms"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bgpEO1_E8MH3",
        "colab_type": "text"
      },
      "source": [
        "There are many image sets in the COWC dataset. We will be working with DetectionPatches set which contains 256 x 256 image patches. It has data from 6 cities. In every city folder, we select the name (like an ID) of each image and append the folder path to the list."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hh8GybNs-rwA",
        "colab_type": "code",
        "outputId": "3d403e69-cc0f-4853-8332-d775e1cb16ea",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "path = './DetectionPatches_256x256/'\n",
        "\n",
        "cities = os.listdir(path)\n",
        "\n",
        "files = []\n",
        "\n",
        "for city in cities:\n",
        "  all_files = os.listdir(path + city + '/')\n",
        "  for file in all_files:\n",
        "    if '.txt' in file:\n",
        "      files.append(path + city + '/' + file.replace('.txt',''))\n",
        "\n",
        "print(len(files))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "29549\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sz2PIZet38TS",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "images = []\n",
        "targets = []\n",
        "\n",
        "transform = transforms.Compose([transforms.ToTensor()])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iZOY7J3GDSnZ",
        "colab_type": "text"
      },
      "source": [
        "Appending the image tensors to the images list. Targets is a list of dictinaries which contains the bounding boxes and the labels information for every image."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4uUQ_Q593_Zs",
        "colab_type": "code",
        "outputId": "65a4bfb1-82a4-4db5-c434-c01e4250788d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "for j in range(len(files)):\n",
        "\tf_path = files[j] + '.jpg'\n",
        "\timg = io.imread(f_path)\n",
        "\timg_tensor = transform(img)\n",
        "\timages.append(img_tensor.double())\n",
        "\n",
        "\tf_path = files[j] + '.txt'\n",
        "\tdf = pd.read_csv(f_path, sep = \" \", header=None)\n",
        "\ttarget = {}\n",
        "\tboxes = []\n",
        "\tlabels = []\n",
        "\tfor i in range(len(df)):\n",
        "\t\tlabels.append(3)\n",
        "\t\tx0 = df.iloc[i,1] - 0.0625\n",
        "\t\tif x0 < 0:\n",
        "\t\t\tx0 = 0\n",
        "\t\ty0 = df.iloc[i,2] - 0.0625\n",
        "\t\tif y0 < 0:\n",
        "\t\t\ty0 = 0\n",
        "\t\tx1 = df.iloc[i,1] + 0.0625\n",
        "\t\tif x1 > 1:\n",
        "\t\t\tx1 = 1\n",
        "\t\ty1 = df.iloc[i,2] + 0.0625\n",
        "\t\tif y1 > 1:\n",
        "\t\t\ty1 = 1\n",
        "\t\tboxes.append([x0,y0,x1,y1])\n",
        "\ttarget['boxes'] = torch.tensor(boxes).double()\n",
        "\ttarget['labels'] = torch.tensor(labels)\n",
        "\n",
        "\ttargets.append(target)\n",
        "\n",
        "\tif (j%4000 == 0):\n",
        "\t\tprint(j)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "46wZEXz-Dp-4",
        "colab_type": "text"
      },
      "source": [
        "Taking Faster R-CNN model with random weights (i.e. without any pre-training). Since it is not a pre-trained model, we can adjust the number of classes as required for our task. The original pre-trained model has 91 classes."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IRBebIJ-4Pwi",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model = models.detection.fasterrcnn_resnet50_fpn(pretrained=False, num_classes=5)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RQcdjx2dD887",
        "colab_type": "text"
      },
      "source": [
        "Fine-tuning a pretrained Faster R-CNN model. In this case, we should not alter the output number of classes."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ImO7y_ofDM5d",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model = models.detection.fasterrcnn_resnet50_fpn(pretrained=True)\n",
        "\n",
        "model = model.float()\n",
        "model.cuda()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2PN24NYIEWr-",
        "colab_type": "text"
      },
      "source": [
        "Training the model with the images and the targets. The loss function used is the sunm of loss classifier and bounding box regression loss. Save the model with the trained weights after every epoch."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rIU5b8jaWxyr",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
        "\n",
        "model.train()\n",
        "running_loss = 0.0\n",
        "\n",
        "for epoch in range(3):\n",
        "\tfor i in range(7000):\n",
        "\t\toptimizer.zero_grad()\n",
        "\t\toutput = model(images[4*i:(4*i)+4], targets[4*i:(4*i)+4])\n",
        "\t\tloss = output['loss_classifier'] + output['loss_box_reg']\n",
        "\t\tloss.backward()\n",
        "\t\toptimizer.step()\n",
        "\t\trunning_loss += loss.item()\n",
        "\n",
        "\t\tif (i+1) % 1000 == 0:\n",
        "\t\t\tprint('[%d, %5d] loss: %.3f' %(epoch + 1, i + 1, running_loss / 25))\n",
        "\t\t\trunning_loss = 0.0\n",
        "\n",
        "\tmodel_path = './model' + '_' + str(epoch+1) + '.pth'\n",
        "\ttorch.save(model.state_dict(), model_path)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WEopaOOSEwmu",
        "colab_type": "text"
      },
      "source": [
        "Load one of the saved models and predict the output bounding boxes and their labels on the test images."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LwF9vG8mnn31",
        "colab_type": "code",
        "outputId": "12741c85-287e-4eca-dbf4-0dacf16b9720",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 72
        }
      },
      "source": [
        "model = models.detection.fasterrcnn_resnet50_fpn(pretrained=True)\n",
        "model.load_state_dict(torch.load('./model_3.pth'))\n",
        "model = model.float().cuda()\n",
        "\n",
        "model.eval()\n",
        "\n",
        "predictions = model(images[2:4])"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/torch/nn/functional.py:2854: UserWarning: The default behavior for interpolate/upsample with float scale_factor will change in 1.6.0 to align with other frameworks/libraries, and use scale_factor directly, instead of relying on the computed output size. If you wish to keep the old behavior, please set recompute_scale_factor=True. See the documentation of nn.Upsample for details. \n",
            "  warnings.warn(\"The default behavior for interpolate/upsample with float scale_factor will change \"\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SY8GoM_BFFja",
        "colab_type": "text"
      },
      "source": [
        "The first element in the output prediction gives the boxes and the labels information."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vm9CGXTwnyEQ",
        "colab_type": "code",
        "outputId": "fe4c3c86-f2bb-4839-9aea-59133e03c56f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 55
        }
      },
      "source": [
        "print(predictions[0])"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "{'boxes': tensor([], device='cuda:0', size=(0, 4), grad_fn=<StackBackward>), 'labels': tensor([], device='cuda:0', dtype=torch.int64), 'scores': tensor([], device='cuda:0', grad_fn=<IndexBackward>)}\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}