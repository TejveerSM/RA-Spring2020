{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Deep Learning Tutorial.ipynb",
      "provenance": [],
      "toc_visible": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UJxqv8_EUsOY",
        "colab_type": "text"
      },
      "source": [
        "# Deep Learning tutorial"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ktMIhxw_VCKw",
        "colab_type": "text"
      },
      "source": [
        "This tutorial teaches the basic aspects of training a deep neural network. The process can be divided broadly into 4 parts:\n",
        "\n",
        "1) Creating a data loader - processing the data into a required format\n",
        "\n",
        "2) Building the neural network\n",
        "\n",
        "3) Training the network\n",
        "\n",
        "4) Evaluating the performance"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "C6yOi39Z3rQp",
        "colab_type": "text"
      },
      "source": [
        "Let's work on a classification problem. The goal is to predict the land scene from an aerial/satellite image."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7nfkX_ZoAqnV",
        "colab_type": "text"
      },
      "source": [
        "We will use PyTorch in this tutorial.\n",
        "\n",
        "First we need to import all the necessary libraries and functions."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Timim5JuUqzS",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from __future__ import print_function, division\n",
        "import os\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "import pandas as pd\n",
        "from skimage import io\n",
        "import numpy as np\n",
        "from torch.utils.data import DataLoader\n",
        "from torchvision import transforms"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qr7KkWLC7U02",
        "colab_type": "text"
      },
      "source": [
        "We can use a GPU if available. The computations and the training process is much faster on a GPU."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Pwhfbsgn6oJt",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "c2j8WkONAyiP",
        "colab_type": "text"
      },
      "source": [
        "We will be working on UC Merced Land Use dataset. It is a 21-class land use image dataset with different classes such as agriculture, buildings, roadways, etc. More information about the dataset can be found here: http://weegee.vision.ucmerced.edu/datasets/landuse.html\n",
        "\n",
        "Download the dataset and unzip the downloaded file."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "W1ODVtvACDsJ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!wget http://weegee.vision.ucmerced.edu/datasets/UCMerced_LandUse.zip\n",
        "\n",
        "!unzip UCMerced_LandUse.zip"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "crPCtUst7vnL",
        "colab_type": "text"
      },
      "source": [
        "We need to store the folder location of the dataset images. A custom .csv file is uploaded. It has all the class/label names and is read to store all the classes."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ylHyHnxl1oy8",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "image_dir = './UCMerced_LandUse/Images/'\n",
        "\n",
        "csv_file = './classes.csv'\n",
        "classes = pd.read_csv(csv_file, header=None)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iAaV2otm8h5M",
        "colab_type": "text"
      },
      "source": [
        "We have downloaded the dataset and now we need to create the DataLoaders which are used in training and testing the network.\n",
        "\n",
        "We need to transform the raw data of the dataset to the required format suitable for training the network. Torchvision package has many image transformations, which can be combined together using Compose.\n",
        "\n",
        "It is good to resize the image to a standard size since some of the images in the dataset might be of different sizes. This ensures uniformity. Randomly flipping the images about horizontal and vertical axes is a good data augmentation technique. It helps the network to learn deeper features. The resize and flip transformations for PIL Image format. So, the input image is first converted to a PIL Image, then resize and flip transformations are applied, and then converted to Torch Tensor format. It is always a good practice to normalize the data before training a model as it generally speeds up the learning and leads to faster convergence.\n",
        "\n",
        "More information and other transforms can be found here: https://pytorch.org/docs/stable/torchvision/transforms.html"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Jp3ZZVL1170L",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "transforms_train = transforms.Compose([ transforms.ToPILImage(), transforms.Resize((256,256)),\n",
        "    transforms.RandomHorizontalFlip(), transforms.RandomVerticalFlip(), \n",
        "    transforms.ToTensor(), transforms.Normalize((0.485, 0.456, 0.406), (0.229, 0.224, 0.225)) ])\n",
        "\n",
        "transforms_test = transforms.Compose([ transforms.ToPILImage(), transforms.Resize((256,256)),\n",
        "    transforms.ToTensor(), transforms.Normalize((0.485, 0.456, 0.406), (0.229, 0.224, 0.225)) ])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ilu3Tc48A_Nl",
        "colab_type": "text"
      },
      "source": [
        "For DataLoaders, we need to have a list of samples where each sample is an image tensor and it's label.\n",
        "\n",
        "Every class has 100 training examples. Here, we divide the first 80 as training samples and the last 20 as testing samples. It is good to randomly mix the samples. Also, it is a good practice to do k-fold cross validation. For more information on k-fold cross validation: https://machinelearningmastery.com/k-fold-cross-validation/\n",
        "\n",
        "Here, ***scikit-image*** is used for reading the image. ***Scikit-image*** is an image processing library for Python. ***io*** is a module used for reading and writing images in various formats. The image is loaded using ***io.imread*** function, transformed to a tensor, and added to the data list along with its label."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "E-rdj9nN2Bj2",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "train_data = []\n",
        "test_data = []\n",
        "\n",
        "for i in range(len(classes)):\n",
        "    for j in range(80):\n",
        "        pth = os.path.join(image_dir, classes.iloc[i,0], classes.iloc[i,0] + str(j).zfill(2) + '.tif')\n",
        "        img = io.imread(pth)\n",
        "        img_tensor = transforms_train(img)\n",
        "        train_data.append([img_tensor, i])\n",
        "\n",
        "    for j in range(20):\n",
        "        pth = os.path.join(image_dir, classes.iloc[i,0], classes.iloc[i,0] + str(j+80).zfill(2) + '.tif')\n",
        "        img = io.imread(pth)\n",
        "        img_tensor = transforms_test(img)\n",
        "        test_data.append([img_tensor, i])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ivvzjd5MrwBJ",
        "colab_type": "text"
      },
      "source": [
        "We need to pass the required batch size to create batches of samples. So, in this case, training and testing dataloaders will have batches of 16 samples each. The general practice is to shuffle the training data, so that there is a mix of examples from different classes in every batch - this leads to training the network better."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1OELKLPl542P",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "TrainDataLoader = DataLoader(train_data, batch_size=16, shuffle=True)\n",
        "TestDataLoader = DataLoader(test_data, batch_size=16, shuffle=False)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LYfXIdPpuUCb",
        "colab_type": "text"
      },
      "source": [
        "We have the data loaders ready and let's build the neural network from scratch (we can also load the pre-built or pre-trained models).\n",
        "\n",
        "We have to define the layers and the forward pass. Since we are working with images with considerably complex features, we have to use convolutional neural networks (CNNs). In CNNs, small matrices called convolution filters are used for convolving with each of the original image pixels to produce a new pixel - the new pixels form a new image/feature map.\n",
        "\n",
        "*nn.Conv2d* applies a 2D convolution over an input signal composed of several input planes. It takes the number of input channels, number of output channels, and the kernel size as the required parameters. It takes other optional parameters like padding and stride. Since we are working with RGB images, the initial number of input channels will be 3. After the first convolution layer, the number of input channels for every convolution layer will be the number of output channels for the previous layer.\n",
        "\n",
        "The input shape of a Conv2d layer is (N, C_in, H_in, W_in) and the output shape is (N, C_out, H_out, W_out) where N is batch size, C is the number of channels, H is the height of the image, and W is the width of the image.\n",
        "\n",
        "More about convolution layers: https://pytorch.org/docs/stable/nn.html#convolution-layers\n",
        "\n",
        "After every convolution layer, the general practice is to add a batch normalization layer to normalize the features. The input shape and the output shape is the same for a batch normalization layer.\n",
        "\n",
        "To introduce non-linearity, we use non-linear activation functions after every convolution such ReLU. ReLU is most common activation function. It applies the rectified linear unit function element-wise: ReLU(x) = max(0,x).\n",
        "\n",
        "Different types of activation functions: https://pytorch.org/docs/stable/nn.html#non-linear-activations-weighted-sum-nonlinearity\n",
        "\n",
        "*nn.MaxPool2d* applies a 2D max pooling - it is a downsampling technique ithat calculates the maximum value in each patch of each feature map/channel. Input shape is (N, C, H, W) and the output shape is (N, C, H_out, W_out). Pooling techniques are used to decrease the dimensionality of the data.\n",
        "\n",
        "Different types of pooling functions: https://pytorch.org/docs/stable/nn.html#pooling-layers\n",
        "\n",
        "The network architecture is defined in the *arch* list. A number signifies the number of output channels of that particular convolutional layer and 'M' signifies a max-pooling layer.\n",
        "\n",
        "*nn.Sequential()* is sequential container, modules will be added to it in the order they are passed in the constructor.\n",
        "\n",
        "After a set of convolutional layers, we need fully-connected layer(s) to classify the features. *nn.Linear()* is used for the fully-connected layers, it applies a linear transformation to the data.\n",
        "\n",
        "The forward pass is defined in the *forward()* method. The images are passed into convolutional layers and the output for every sample is a 3D tensor. The 3D array/tensor is flattened to get a linear vector i.e. converting the features into a single dimension and then passed through the fully-connected layers to get the final output. The forward method determines the flow of data within the network."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TsZAoHa22GMy",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "arch = [16, 16, 'M', 64, 64, 'M', 128, 128, 'M', 256, 'M', 256, 'M', 256, 'M', 256, 'M']\n",
        "\n",
        "class Net(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(Net, self).__init__()\n",
        "        self.features = self._make_layers(arch)\n",
        "        self.fc1 = nn.Linear(1024,1024)\n",
        "        self.fc2 = nn.Linear(1024,21)\n",
        "\n",
        "    def forward(self, I):\n",
        "        out = self.features(I)\n",
        "        out = out.view(out.size(0), -1)\n",
        "        out = self.fc1(out)\n",
        "        out = self.fc2(out)\n",
        "        return out\n",
        "\n",
        "    def _make_layers(self, arch):\n",
        "        layers = []\n",
        "        in_channels = 3\n",
        "        for x in arch:\n",
        "            if x == 'M':\n",
        "                layers += [nn.MaxPool2d(kernel_size=2, stride=2)]\n",
        "            else:\n",
        "                layers += [nn.Conv2d(in_channels, x, kernel_size=3, padding=1),\n",
        "                           nn.BatchNorm2d(x),\n",
        "                           nn.ReLU(inplace=True)]\n",
        "                in_channels = x\n",
        "        return nn.Sequential(*layers)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QAS6BAkKrur0",
        "colab_type": "text"
      },
      "source": [
        "A network object is created and loaded onto the GPU device, if available, for faster computations."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fLt2utKv6gli",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "net = Net()\n",
        "net.to(device)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yqij02oxshRB",
        "colab_type": "text"
      },
      "source": [
        "Now, let's define all the required parameters for training the network and evaluating the performance.\n",
        "\n",
        "We need to use a loss function to calculate the loss values, it is like a metric to measure the difference between actual and expected values. PyTorch gives many loss functions: https://pytorch.org/docs/stable/nn.html#loss-functions. Different loss functions work well with different tasks. Cross entropy loss is the most commonly used loss function for classification problems.\n",
        "\n",
        "Updating the network weights/parameters is the most important part in training a network. *torch.optim* package gives different types of optimizers. Most common optimizations are Stochastic Gradient Descent (SGD) and Adam. The general practice is to start with a relatively large learning rate (of about 0.01) and gradually decrease it. So, a scheduler is used to decrease the learning by a factor (gamma) after every certain number of epochs (step size). Loss function, optimizer, learning rate, weight decay are hyperparameters which need to be tuned to achieve better accuracies. Different set of values work well for different networks and tasks."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zzzdm4d26uvu",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "num_epochs = 50\n",
        "\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = optim.SGD(net.parameters(), lr=0.01, momentum=0.8, weight_decay=0.02)\n",
        "scheduler = optim.lr_scheduler.StepLR(optimizer, step_size=10, gamma=0.5)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "v5o_E5yaxUy5",
        "colab_type": "text"
      },
      "source": [
        "*.train()* sets the model to training mode. A batch of images and labels are passed through the network, outputs are obtained, loss values are calculated and backpropagated, and finally the weights are updated. The cumulative running loss is calculated and displayed after processing a every few batches. The loss values should decrease as the network gets trained.\n",
        "\n",
        "*.eval()* sets the model to inference mode. Training and test accuracies are calculated. Test accuracy is our primary interest and the actual evaluation metric. Training accuracy can go up to 100% which means there is model overfitting. As the network gets trained, test accuracy converges. There is a possibility that test accuracy can drop after a certain point of time. So, to keep track, we calculate the best epoch and the best test accuracy after every epoch and save the best model up to that point. After every epoch, we do *scheduler.step()* to update the learning rate."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2_uoNX3B2VIs",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "best_test_acc = 0\n",
        "best_epoch = -1\n",
        "\n",
        "PATH = './trained_model.pth'\n",
        "\n",
        "for epoch in range(num_epochs):\n",
        "\n",
        "    net.train()\n",
        "\n",
        "    running_loss = 0.0\n",
        "    for batch_no, (images, labels) in enumerate(TrainDataLoader):\n",
        "        optimizer.zero_grad()\n",
        "        images = images.to(device)\n",
        "        labels = labels.to(device)\n",
        "        outputs = net(images)\n",
        "        loss = criterion(outputs, labels)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "        running_loss += loss.item()\n",
        "        if batch_no % 25 == 24:\n",
        "            print('[%d, %5d] loss: %.3f' %(epoch + 1, batch_no + 1, running_loss / 25))\n",
        "            running_loss = 0.0\n",
        "\n",
        "    net.eval()\n",
        "\n",
        "    correct = 0\n",
        "    total = 0\n",
        "    with torch.no_grad():\n",
        "        for data in TrainDataLoader:\n",
        "            images, labels = data[0].to(device), data[1].to(device)\n",
        "            outputs = net(images)\n",
        "            _,predicted = torch.max(outputs.data,1)\n",
        "            total += labels.size(0)\n",
        "            correct += (predicted == labels).sum().item()\n",
        "    train_acc = np.around(correct/total*100, decimals=2)\n",
        "    print('TRAIN ACCURACY:', train_acc)\n",
        "\n",
        "    correct = 0\n",
        "    total = 0\n",
        "    with torch.no_grad():\n",
        "        for data in TestDataLoader:\n",
        "            images, labels = data[0].to(device), data[1].to(device)\n",
        "            outputs = net(images)\n",
        "            _,predicted = torch.max(outputs.data,1)\n",
        "            total += labels.size(0)\n",
        "            correct += (predicted == labels).sum().item()\n",
        "    test_acc = np.around(correct/total*100, decimals=2)\n",
        "    print('TEST ACCURACY:', test_acc)\n",
        "\n",
        "    if test_acc > best_test_acc:\n",
        "        best_test_acc = test_acc\n",
        "        best_epoch = epoch+1\n",
        "        torch.save(net.state_dict(), PATH)\n",
        "\n",
        "    scheduler.step()\n",
        "    print()\n",
        "\n",
        "print('Best test accuracy:', best_test_acc)\n",
        "print('Best epoch:', best_epoch)"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}